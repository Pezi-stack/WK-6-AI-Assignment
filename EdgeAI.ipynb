{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6480a162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Recyclable Items Classification with TensorFlow Lite ===\n",
      "\n",
      "Creating synthetic dataset for recyclable items...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173056</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173056\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │    \u001b[38;5;34m11,075,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,132,358</span> (42.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,132,358\u001b[0m (42.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,132,358</span> (42.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,132,358\u001b[0m (42.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with synthetic data...\n",
      "(In practice, use real waste classification datasets)\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Dell\\AppData\\Local\\Temp\\tmpg0b8b830\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Dell\\AppData\\Local\\Temp\\tmpg0b8b830\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Dell\\AppData\\Local\\Temp\\tmpg0b8b830'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1558971586832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1558971588560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1558971587600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1558971587024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1558971587792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1558997630416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1558971587984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1558997630608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1558998532176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1558998533712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "TensorFlow Lite model saved: recycling_classifier.tflite\n",
      "Model size: 21747.37 KB\n",
      "\n",
      "TensorFlow Lite Model Details:\n",
      "Input shape: [  1 224 224   3]\n",
      "Input type: <class 'numpy.float32'>\n",
      "Output shape: [1 6]\n",
      "Output type: <class 'numpy.float32'>\n",
      "\n",
      "Test Prediction: plastic\n",
      "Confidence scores: {'plastic': '0.201', 'paper': '0.164', 'glass': '0.152', 'metal': '0.192', 'cardboard': '0.139', 'trash': '0.151'}\n",
      "\n",
      "=== Model Conversion Complete ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Create synthetic dataset (in practice, you'd use real images)\n",
    "def create_synthetic_dataset():\n",
    "    # This simulates having a dataset of recyclable items\n",
    "    # In reality, you'd use datasets like:\n",
    "    # - Waste Classification dataset\n",
    "    # - TrashNet dataset\n",
    "    # - Custom collected images\n",
    "    \n",
    "    # For demonstration, we'll create a simple CNN model structure\n",
    "    # and use synthetic data generation\n",
    "    \n",
    "    print(\"Creating synthetic dataset for recyclable items...\")\n",
    "    \n",
    "    # Define class names\n",
    "    class_names = ['plastic', 'paper', 'glass', 'metal', 'cardboard', 'trash']\n",
    "    \n",
    "    return class_names\n",
    "\n",
    "# Build the model\n",
    "def build_recycling_classifier(input_shape=(224, 224, 3), num_classes=6):\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        \n",
    "        # Classifier Head\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train the model (with synthetic data simulation)\n",
    "def train_model():\n",
    "    class_names = create_synthetic_dataset()\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    # Build model\n",
    "    model = build_recycling_classifier(num_classes=num_classes)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"Model architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # In a real scenario, you would load your actual dataset here\n",
    "    # For demonstration, we'll create synthetic training results\n",
    "    print(\"\\nTraining model with synthetic data...\")\n",
    "    print(\"(In practice, use real waste classification datasets)\")\n",
    "    \n",
    "    # Simulate training process\n",
    "    history = {\n",
    "        'accuracy': [0.45, 0.68, 0.78, 0.82, 0.85],\n",
    "        'val_accuracy': [0.42, 0.65, 0.75, 0.79, 0.81],\n",
    "        'loss': [1.2, 0.8, 0.6, 0.45, 0.35],\n",
    "        'val_loss': [1.3, 0.9, 0.7, 0.55, 0.45]\n",
    "    }\n",
    "    \n",
    "    return model, history, class_names\n",
    "\n",
    "# Convert to TensorFlow Lite\n",
    "def convert_to_tflite(model):\n",
    "    # Convert to TensorFlow Lite\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    \n",
    "    # Optimize for size and speed\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    \n",
    "    # Optional: Use float16 quantization for smaller size\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    # Save the model\n",
    "    with open('recycling_classifier.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(f\"TensorFlow Lite model saved: recycling_classifier.tflite\")\n",
    "    print(f\"Model size: {len(tflite_model) / 1024:.2f} KB\")\n",
    "    \n",
    "    return tflite_model\n",
    "\n",
    "# Test TensorFlow Lite model\n",
    "def test_tflite_model(tflite_model, class_names):\n",
    "    # Load TFLite model and allocate tensors\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    # Get input and output tensors\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    print(\"\\nTensorFlow Lite Model Details:\")\n",
    "    print(f\"Input shape: {input_details[0]['shape']}\")\n",
    "    print(f\"Input type: {input_details[0]['dtype']}\")\n",
    "    print(f\"Output shape: {output_details[0]['shape']}\")\n",
    "    print(f\"Output type: {output_details[0]['dtype']}\")\n",
    "    \n",
    "    # Test with random input (simulating real image)\n",
    "    input_shape = input_details[0]['shape']\n",
    "    test_input = np.random.random_sample(input_shape).astype(np.float32)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], test_input)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    predicted_class = np.argmax(output_data[0])\n",
    "    \n",
    "    print(f\"\\nTest Prediction: {class_names[predicted_class]}\")\n",
    "    print(\"Confidence scores:\", {name: f\"{score:.3f}\" for name, score in zip(class_names, output_data[0])})\n",
    "    \n",
    "    return interpreter\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Recyclable Items Classification with TensorFlow Lite ===\\n\")\n",
    "    \n",
    "    # Train model\n",
    "    model, history, class_names = train_model()\n",
    "    \n",
    "    # Convert to TensorFlow Lite\n",
    "    tflite_model = convert_to_tflite(model)\n",
    "    \n",
    "    # Test the TFLite model\n",
    "    interpreter = test_tflite_model(tflite_model, class_names)\n",
    "    \n",
    "    print(\"\\n=== Model Conversion Complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0458f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with synthetic data...\n",
      "Image 1: plastic (confidence: 0.191)\n",
      "Image 2: plastic (confidence: 0.192)\n",
      "Image 3: plastic (confidence: 0.190)\n",
      "\n",
      "=== Performance Benchmarking ===\n",
      "Average inference time: 12.66 ms\n",
      "Standard deviation: 1.05 ms\n",
      "Max FPS: 79.0 frames per second\n"
     ]
    }
   ],
   "source": [
    "# deployment_test.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class RecyclingClassifier:\n",
    "    def __init__(self, model_path):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "        self.interpreter.allocate_tensors()\n",
    "        \n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "        \n",
    "        self.class_names = ['plastic', 'paper', 'glass', 'metal', 'cardboard', 'trash']\n",
    "    \n",
    "    def preprocess_image(self, image_array):\n",
    "        \"\"\"Preprocess image for the model\"\"\"\n",
    "        # Resize to model input size\n",
    "        image = tf.image.resize(image_array, (224, 224))\n",
    "        # Normalize to [0, 1]\n",
    "        image = image / 255.0\n",
    "        # Add batch dimension\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "        return image.numpy().astype(np.float32)\n",
    "    \n",
    "    def classify(self, image_array):\n",
    "        \"\"\"Classify an image\"\"\"\n",
    "        # Preprocess\n",
    "        processed_image = self.preprocess_image(image_array)\n",
    "        \n",
    "        # Set input tensor\n",
    "        self.interpreter.set_tensor(self.input_details[0]['index'], processed_image)\n",
    "        \n",
    "        # Run inference\n",
    "        self.interpreter.invoke()\n",
    "        \n",
    "        # Get output\n",
    "        output_data = self.interpreter.get_tensor(self.output_details[0]['index'])\n",
    "        predictions = output_data[0]\n",
    "        \n",
    "        # Get results\n",
    "        predicted_class_idx = np.argmax(predictions)\n",
    "        confidence = predictions[predicted_class_idx]\n",
    "        \n",
    "        return {\n",
    "            'class': self.class_names[predicted_class_idx],\n",
    "            'confidence': float(confidence),\n",
    "            'all_predictions': {\n",
    "                name: float(score) for name, score in zip(self.class_names, predictions)\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Test with synthetic images\n",
    "def test_with_synthetic_data():\n",
    "    print(\"Testing with synthetic data...\")\n",
    "    \n",
    "    # Load model\n",
    "    classifier = RecyclingClassifier('recycling_classifier.tflite')\n",
    "    \n",
    "    # Create synthetic test images (in practice, use real images)\n",
    "    test_images = [\n",
    "        np.random.rand(300, 300, 3) * 255,  # Simulate plastic bottle\n",
    "        np.random.rand(300, 300, 3) * 255,  # Simulate paper\n",
    "        np.random.rand(300, 300, 3) * 255,  # Simulate glass\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for i, image in enumerate(test_images):\n",
    "        result = classifier.classify(image)\n",
    "        results.append(result)\n",
    "        print(f\"Image {i+1}: {result['class']} (confidence: {result['confidence']:.3f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Performance benchmarking\n",
    "def benchmark_model():\n",
    "    print(\"\\n=== Performance Benchmarking ===\")\n",
    "    \n",
    "    # Load model\n",
    "    classifier = RecyclingClassifier('recycling_classifier.tflite')\n",
    "    \n",
    "    # Benchmark inference time\n",
    "    test_image = np.random.rand(300, 300, 3) * 255\n",
    "    \n",
    "    import time\n",
    "    times = []\n",
    "    for _ in range(100):\n",
    "        start_time = time.time()\n",
    "        classifier.classify(test_image)\n",
    "        end_time = time.time()\n",
    "        times.append((end_time - start_time) * 1000)  # Convert to ms\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    std_time = np.std(times)\n",
    "    \n",
    "    print(f\"Average inference time: {avg_time:.2f} ms\")\n",
    "    print(f\"Standard deviation: {std_time:.2f} ms\")\n",
    "    print(f\"Max FPS: {1000/avg_time:.1f} frames per second\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test classification\n",
    "    results = test_with_synthetic_data()\n",
    "    \n",
    "    # Benchmark performance\n",
    "    benchmark_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab3d498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
